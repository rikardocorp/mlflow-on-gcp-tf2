{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "# import logging\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from builtins import int\n",
    "from mlflow import pyfunc\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from time import time\n",
    "\n",
    "class DictX(dict):\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError as k:\n",
    "            raise AttributeError(k)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "    def __delattr__(self, key):\n",
    "        try:\n",
    "            del self[key]\n",
    "        except KeyError as k:\n",
    "            raise AttributeError(k)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<DictX ' + dict.__repr__(self) + '>'\n",
    "\n",
    "def _mlflow_log_metrics(metrics, metric_name):\n",
    "    \"\"\"Record metric value during each epoch using the step parameter in\n",
    "    mlflow.log_metric.\n",
    "\n",
    "    :param metrics:\n",
    "    :param metric_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for epoch, metric in enumerate(metrics[metric_name], 1): mlflow.log_metric(\n",
    "        metric_name, metric,\n",
    "        step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), 'trainer')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import utils\n",
    "import model_deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def info(self, text):\n",
    "        print(text)\n",
    "\n",
    "logging = Log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'reuse_job_dir': False,\n",
    "    'job_dir': 'mlflow',\n",
    "    'train_files':'gs://cloud-samples-data/ml-engine/census/data/adult.data.csv',\n",
    "    'eval_files': 'gs://cloud-samples-data/ml-engine/census/data/adult.test.csv',\n",
    "    'learning_rate': .01,\n",
    "    'num_epochs': 5,\n",
    "    'batch_size': 128,\n",
    "    'eval_steps':1\n",
    "}\n",
    "args = DictX(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "if not args.reuse_job_dir:\n",
    "    print('paso')\n",
    "    print(tf.io.gfile.exists(args.job_dir))\n",
    "    if tf.io.gfile.exists(args.job_dir):\n",
    "        tf.io.gfile.rmtree(args.job_dir)\n",
    "        logging.info(\n",
    "            'Deleted job_dir {} to avoid re-use'.format(args.job_dir))\n",
    "else:\n",
    "    logging.info('Reusing job_dir {} if it exists'.format(args.job_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing job_dir mlflow if it exists\n"
     ]
    }
   ],
   "source": [
    "logging.info('Reusing job_dir {} if it exists'.format(args.job_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location train file: gs://cloud-samples-data/ml-engine/census/data/adult.data.csv, eval file gs://cloud-samples-data/ml-engine/census/data/adult.test.csv\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, eval_x, eval_y = utils.load_data(args.train_files, args.eval_files)\n",
    "# dimensions\n",
    "num_train_examples, input_dim = train_x.shape\n",
    "num_eval_examples = eval_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Model\n",
    "keras_model = model.create_keras_model(input_dim=input_dim, learning_rate=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass a numpy array by passing DataFrame.values\n",
    "training_dataset = model.input_fn(\n",
    "    features=train_x.values,\n",
    "    labels=train_y,\n",
    "    shuffle=True,\n",
    "    num_epochs=args.num_epochs,\n",
    "    batch_size=args.batch_size)\n",
    "\n",
    "# Pass a numpy array by passing DataFrame.values\n",
    "validation_dataset = model.input_fn(\n",
    "    features=eval_x.values,\n",
    "    labels=eval_y,\n",
    "    shuffle=False,\n",
    "    num_epochs=args.num_epochs,\n",
    "    batch_size=num_eval_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as active_run:\n",
    "    run_id = active_run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'976a46c4c2d0445cb50d330c801a00b8'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow.end_run()\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class MlflowCallback(tf.keras.callbacks.Callback):\n",
    "    # This function will be called after training completes.\n",
    "    def on_train_end(self, logs=None):\n",
    "        mlflow.log_param('num_layers', len(self.model.layers))\n",
    "        mlflow.log_param('optimizer_name',\n",
    "                         type(self.model.optimizer).__name__)\n",
    "# MLflow callback\n",
    "mlflow_callback = MlflowCallback()\n",
    "# Setup Learning Rate decay callback.\n",
    "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: args.learning_rate + 0.02 * (0.5 ** (1 + epoch)),\n",
    "    verbose=False)\n",
    "# Setup TensorBoard callback.\n",
    "tensorboard_path = os.path.join(args.job_dir, run_id, 'tensorboard')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    tensorboard_path,\n",
    "    histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = model.create_keras_model(input_dim=input_dim, learning_rate=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  2/254 [..............................] - ETA: 35s - loss: 10.5697 - accuracy: 0.7578WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_begin` time: 0.0060s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.2740s). Check your callbacks.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.5313 - accuracy: 0.7940 - val_loss: 0.3696 - val_accuracy: 0.8340\n",
      "Epoch 2/5\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8321 - val_loss: 0.3315 - val_accuracy: 0.8446\n",
      "Epoch 3/5\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8422 - val_loss: 0.3350 - val_accuracy: 0.8406\n",
      "Epoch 4/5\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8431 - val_loss: 0.3272 - val_accuracy: 0.8469\n",
      "Epoch 5/5\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8462 - val_loss: 0.3297 - val_accuracy: 0.8472\n"
     ]
    }
   ],
   "source": [
    "history = keras_model.fit(\n",
    "    training_dataset,\n",
    "    steps_per_epoch=int(num_train_examples / args.batch_size),\n",
    "    epochs=args.num_epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=args.eval_steps,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_decay_callback, tensorboard_callback,\n",
    "               mlflow_callback])\n",
    "metrics = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5243113040924072,\n",
       "  0.37130650877952576,\n",
       "  0.3430071175098419,\n",
       "  0.3362666368484497,\n",
       "  0.33429110050201416],\n",
       " 'accuracy': [0.7890625,\n",
       "  0.8304625749588013,\n",
       "  0.8407357335090637,\n",
       "  0.8441498279571533,\n",
       "  0.8464567065238953],\n",
       " 'val_loss': [0.39031627774238586,\n",
       "  0.355435311794281,\n",
       "  0.33384740352630615,\n",
       "  0.33359837532043457,\n",
       "  0.3242957293987274],\n",
       " 'val_accuracy': [0.8184052109718323,\n",
       "  0.8338862061500549,\n",
       "  0.8491215109825134,\n",
       "  0.8453741073608398,\n",
       "  0.850411593914032],\n",
       " 'lr': [0.02, 0.015, 0.0125, 0.01125, 0.010625]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 13,876\n",
      "Trainable params: 13,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()\n",
    "mlflow.log_param('train_files', args.train_files)\n",
    "mlflow.log_param('eval_files', args.eval_files)\n",
    "mlflow.log_param('num_epochs', args.num_epochs)\n",
    "mlflow.log_param('batch_size', args.batch_size)\n",
    "mlflow.log_param('learning_rate', args.learning_rate)\n",
    "mlflow.log_param('train_samples', num_train_examples)\n",
    "mlflow.log_param('eval_samples', num_eval_examples)\n",
    "mlflow.log_param('eval_steps', args.eval_steps)\n",
    "mlflow.log_param('steps_per_epoch',\n",
    "                 int(num_train_examples / args.batch_size))\n",
    "# Add metrics\n",
    "_mlflow_log_metrics(metrics, 'loss')\n",
    "_mlflow_log_metrics(metrics, 'accuracy')\n",
    "_mlflow_log_metrics(metrics, 'val_loss')\n",
    "_mlflow_log_metrics(metrics, 'val_accuracy')\n",
    "_mlflow_log_metrics(metrics, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_path = os.path.join(args.job_dir, run_id, 'model')\n",
    "# model_local_path = 'model3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = [[1,2,3,4]]\n",
    "np.save(model_local_path, a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "data_dir_raw = Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_path = data_dir_raw / args.job_dir / run_id / 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('mlflow/976a46c4c2d0445cb50d330c801a00b8/model')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_path = 'mlflow/976a46c4c2d/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mlflow/976a46c4c2d/model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(\n",
    "    keras_model, model_local_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a NewWriteableFile: mlflow\\7e1b6daeea0e4d988ad3f0c2595c3aaa\\model\\variables\\variables_temp_4a16e86dff25474b962377846c108e7e/part-00000-of-00001.data-00000-of-00001.tempstate9155103110247276991 : El sistema no puede encontrar la ruta especificada.\r\n; No such process [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1f9c1e6023cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_local_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(model_local_path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_local_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# Define artifacts.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model exported to: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_local_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    983\u001b[0m       experimental_io_device=options.experimental_io_device)\n\u001b[0;32m    984\u001b[0m   object_saver.save(utils_impl.get_variables_path(export_dir),\n\u001b[1;32m--> 985\u001b[1;33m                     options=ckpt_options)\n\u001b[0m\u001b[0;32m    986\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n\u001b[0;32m    987\u001b[0m                                               export_dir)\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1200\u001b[1;33m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0m\u001b[0;32m   1201\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1144\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    267\u001b[0m           \u001b[1;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m           \u001b[1;31m# device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m           \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[0;32m   1729\u001b[0m       return save_v2_eager_fallback(\n\u001b[0;32m   1730\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1731\u001b[1;33m           ctx=_ctx)\n\u001b[0m\u001b[0;32m   1732\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[0;32m   1749\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"dtypes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 1751\u001b[1;33m                              ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m   1752\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0104\\appdata\\local\\continuum\\anaconda3\\envs\\mlflow-tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: mlflow\\7e1b6daeea0e4d988ad3f0c2595c3aaa\\model\\variables\\variables_temp_4a16e86dff25474b962377846c108e7e/part-00000-of-00001.data-00000-of-00001.tempstate9155103110247276991 : El sistema no puede encontrar la ruta especificada.\r\n; No such process [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "model_local_path = os.path.join(args.job_dir, run_id, 'model')\n",
    "# print(model_local_path)\n",
    "tf.saved_model.save(keras_model, model_local_path)\n",
    "# Define artifacts.\n",
    "logging.info('Model exported to: {}'.format(model_local_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
